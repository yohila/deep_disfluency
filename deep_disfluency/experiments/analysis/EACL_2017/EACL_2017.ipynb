{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Computes the accuracies for the outputs from the EACL 2017 experiments on\n",
    "#joint incremental utterance segmentation and disfluency detection\n",
    "#this assumes the experiments are in simple_rnn_disf/rnn_disf_detection/experiments/\n",
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "sys.path.append(\"../../../../\")\n",
    "# from mumodo.mumodoIO import open_intervalframe_from_textgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add the evaluation module functions\n",
    "from deep_disfluency.evaluation.disf_evaluation import incremental_output_disfluency_eval_from_file\n",
    "from deep_disfluency.evaluation.disf_evaluation import final_output_disfluency_eval_from_file\n",
    "from deep_disfluency.evaluation.eval_utils import get_tag_data_from_corpus_file\n",
    "from deep_disfluency.evaluation.eval_utils import rename_all_repairs_in_line_with_index\n",
    "from deep_disfluency.evaluation.eval_utils import sort_into_dialogue_speakers\n",
    "from deep_disfluency.evaluation.results_utils import convert_to_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the locations of all needed files\n",
    "# Assume we have the incremental output\n",
    "experiment_dir = \"../../../experiments\"\n",
    "\n",
    "partial_words = True  # No partial words in these experiments, removed\n",
    "if partial_words:\n",
    "    partial = '_partial'\n",
    "else:\n",
    "    partial = ''\n",
    "#the evaluation files (as text files)\n",
    "disf_dir = \"../../../data/disfluency_detection/switchboard\"\n",
    "disfluency_files = [\n",
    "                    disf_dir + \"/swbd_disf_heldout{}_data_timings.csv\".format(partial),\n",
    "                    disf_dir + \"/swbd_disf_test{}_data_timings.csv\".format(partial)\n",
    "                   ]\n",
    "allsystemsfinal = [\n",
    "                   (\"033/epoch_45\", 'RNN (joint task)'),\n",
    "                   (\"034/epoch_37\", 'RNN (complex tags) (joint task)'),\n",
    "                   (\"035/epoch_6\", 'LSTM (joint task)'),\n",
    "                   (\"036/epoch_15\", 'LSTM (complex tags) (joint task)'),\n",
    "                   (\"037/epoch_6\", 'LSTM (disf only)'),\n",
    "                   (\"038/epoch_8\", 'LSTM (uttseg only)'),\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "div_dir = \"../../../data/disfluency_detection/swda_divisions_disfluency_detection\"\n",
    "good_asr_heldout = [line.strip(\"\\n\") for line in open(\n",
    "        \"{}/swbd_disf_heldout_ASR_good_ranges.text\".format(div_dir))]\n",
    "good_asr_test = [line.strip(\"\\n\") for line in open(\n",
    "        \"{}/swbd_disf_test_ASR_good_ranges.text\".format(div_dir))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Evaluation (and creation of final output files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM: 033/epoch_45 RNN (joint task)\n",
      "timings False\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julian/.local/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing final output to file ../../../experiments/033/epoch_45/swbd_disf_heldout_partial_data_output_final.text\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/033/epoch_45/swbd_disf_test_partial_data_output_final.text\n",
      "timings True\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/033/epoch_45/swbd_disf_heldout_partial_timings_data_output_final.text\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/033/epoch_45/swbd_disf_test_partial_timings_data_output_final.text\n",
      "SYSTEM: 034/epoch_37 RNN (complex tags) (joint task)\n",
      "timings False\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/034/epoch_37/swbd_disf_heldout_partial_data_output_final.text\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/034/epoch_37/swbd_disf_test_partial_data_output_final.text\n",
      "timings True\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/034/epoch_37/swbd_disf_heldout_partial_timings_data_output_final.text\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/034/epoch_37/swbd_disf_test_partial_timings_data_output_final.text\n",
      "SYSTEM: 035/epoch_6 LSTM (joint task)\n",
      "timings False\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/035/epoch_6/swbd_disf_heldout_partial_data_output_final.text\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/035/epoch_6/swbd_disf_test_partial_data_output_final.text\n",
      "timings True\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/035/epoch_6/swbd_disf_heldout_partial_timings_data_output_final.text\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/035/epoch_6/swbd_disf_test_partial_timings_data_output_final.text\n",
      "SYSTEM: 036/epoch_15 LSTM (complex tags) (joint task)\n",
      "timings False\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/036/epoch_15/swbd_disf_heldout_partial_data_output_final.text\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/036/epoch_15/swbd_disf_test_partial_data_output_final.text\n",
      "timings True\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/036/epoch_15/swbd_disf_heldout_partial_timings_data_output_final.text\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/036/epoch_15/swbd_disf_test_partial_timings_data_output_final.text\n",
      "SYSTEM: 037/epoch_6 LSTM (disf only)\n",
      "timings False\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= False\n",
      "writing final output to file ../../../experiments/037/epoch_6/swbd_disf_heldout_partial_data_output_final.text\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= False\n",
      "writing final output to file ../../../experiments/037/epoch_6/swbd_disf_test_partial_data_output_final.text\n",
      "timings True\n",
      "SYSTEM: 038/epoch_8 LSTM (uttseg only)\n",
      "timings False\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/038/epoch_8/swbd_disf_heldout_partial_data_output_final.text\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/038/epoch_8/swbd_disf_test_partial_data_output_final.text\n",
      "timings True\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/038/epoch_8/swbd_disf_heldout_partial_timings_data_output_final.text\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "writing final output to file ../../../experiments/038/epoch_8/swbd_disf_test_partial_timings_data_output_final.text\n"
     ]
    }
   ],
   "source": [
    "# create final output files for the final output evaluation (and do incremental evaluation first:\n",
    "# NB this takes a while! 5-10 mins per system\n",
    "DO_INCREMENTAL_EVAL = True\n",
    "VERBOSE = False\n",
    "if DO_INCREMENTAL_EVAL:\n",
    "    all_incremental_results = {}\n",
    "    all_incremental_error_dicts = {}\n",
    "    for system, system_name in allsystemsfinal:\n",
    "        print \"SYSTEM:\", system, system_name\n",
    "        #if 'complex' in system: break\n",
    "        for timings_string in [\n",
    "                               \"\", \n",
    "                               \"_timings\"\n",
    "                              ]:  # without and with timings\n",
    "            print \"timings\", timings_string!=\"\"\n",
    "            if timings_string == \"_timings\" and \"disf only\" in system_name:\n",
    "                continue\n",
    "            hyp_dir = experiment_dir + \"/\" + system\n",
    "            #hyp_dir = experiment_dir\n",
    "            for division, disf_file in zip([\"heldout\", \"test\"], disfluency_files):\n",
    "                print \"*\" * 30, division, \"*\" * 30\n",
    "                IDs, timings, words, pos_tags, labels = get_tag_data_from_corpus_file(disf_file)\n",
    "                gold_data = {} #map from the file name to the data\n",
    "                for dialogue,a,b,c,d in zip(IDs, timings, words, pos_tags, labels):\n",
    "                    # if \"asr\" in division and not dialogue[:4] in good_asr: continue\n",
    "                    gold_data[dialogue] = (a,b,c,d)\n",
    "                inc_filename = hyp_dir + \"/swbd_disf_{0}{1}{2}_data_output_increco\".format(\n",
    "                    division, partial, timings_string) + \".text\"\n",
    "                final_output_name = inc_filename.replace(\"_increco\", \"_final\")\n",
    "                results, error_analysis = incremental_output_disfluency_eval_from_file(\n",
    "                                                     inc_filename,\n",
    "                                                     gold_data,\n",
    "                                                     utt_eval=\"disf only\" not in system_name,\n",
    "                                                     error_analysis=True,\n",
    "                                                     word=True,\n",
    "                                                     interval=True,\n",
    "                                                     outputfilename=final_output_name\n",
    "                                                                                      )\n",
    "                if VERBOSE:\n",
    "                    for k,v in results.items():\n",
    "                        print k,v\n",
    "                r_key = division + \"_\" + system + timings_string\n",
    "                all_incremental_results[r_key] = deepcopy(results)\n",
    "                if \"heldout\" in division:\n",
    "                    # only do the error analyses on the heldout data\n",
    "                    e_key = division + \"_\" + system + timings_string\n",
    "                    all_incremental_error_dicts[e_key] = deepcopy(error_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_038/epoch_8', 'heldout_036/epoch_15_timings', 'heldout_034/epoch_37', 'heldout_034/epoch_37_timings', 'heldout_033/epoch_45', 'test_035/epoch_6_timings', 'test_037/epoch_6', 'heldout_038/epoch_8_timings', 'test_036/epoch_15_timings', 'heldout_035/epoch_6_timings', 'test_033/epoch_45_timings', 'test_035/epoch_6', 'heldout_038/epoch_8', 'heldout_033/epoch_45_timings', 'heldout_035/epoch_6', 'test_034/epoch_37', 'heldout_037/epoch_6', 'heldout_036/epoch_15', 'test_033/epoch_45', 'test_038/epoch_8_timings', 'test_034/epoch_37_timings', 'test_036/epoch_15']\n",
      "Part of table 4. in the paper\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System (eval. method)</th>\n",
       "      <th>TTD$_{tto}$ (time in s)</th>\n",
       "      <th>TTD$_{rps}$ (word)</th>\n",
       "      <th>EO (word)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM joint task (transcript)</td>\n",
       "      <td>0.458</td>\n",
       "      <td>1.006</td>\n",
       "      <td>13.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM joint task (+timing) (transcript)</td>\n",
       "      <td>0.648</td>\n",
       "      <td>1.003</td>\n",
       "      <td>11.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM joint task (complex) (transcript)</td>\n",
       "      <td>0.676</td>\n",
       "      <td>1.084</td>\n",
       "      <td>11.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM joint task (complex) (+timing) (transcript)</td>\n",
       "      <td>0.931</td>\n",
       "      <td>1.081</td>\n",
       "      <td>9.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSTM single disfluency task (transcript)</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.000</td>\n",
       "      <td>7.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSTM single uttseg task (transcript)</td>\n",
       "      <td>0.559</td>\n",
       "      <td>nan</td>\n",
       "      <td>8.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSTM single uttseg task (+timing) (transcript)</td>\n",
       "      <td>0.835</td>\n",
       "      <td>nan</td>\n",
       "      <td>6.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RNN joint task (transcript)</td>\n",
       "      <td>0.531</td>\n",
       "      <td>1.017</td>\n",
       "      <td>11.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RNN joint task (+timing) (transcript)</td>\n",
       "      <td>0.715</td>\n",
       "      <td>1.011</td>\n",
       "      <td>10.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RNN joint task (complex) (transcript)</td>\n",
       "      <td>0.799</td>\n",
       "      <td>1.119</td>\n",
       "      <td>9.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RNN joint task (complex) (+timing) (transcript)</td>\n",
       "      <td>1.081</td>\n",
       "      <td>1.103</td>\n",
       "      <td>8.233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               System (eval. method) TTD$_{tto}$ (time in s)  \\\n",
       "0                       LSTM joint task (transcript)                   0.458   \n",
       "1             LSTM joint task (+timing) (transcript)                   0.648   \n",
       "2             LSTM joint task (complex) (transcript)                   0.676   \n",
       "3   LSTM joint task (complex) (+timing) (transcript)                   0.931   \n",
       "4           LSTM single disfluency task (transcript)                     nan   \n",
       "5               LSTM single uttseg task (transcript)                   0.559   \n",
       "6     LSTM single uttseg task (+timing) (transcript)                   0.835   \n",
       "7                        RNN joint task (transcript)                   0.531   \n",
       "8              RNN joint task (+timing) (transcript)                   0.715   \n",
       "9              RNN joint task (complex) (transcript)                   0.799   \n",
       "10   RNN joint task (complex) (+timing) (transcript)                   1.081   \n",
       "\n",
       "   TTD$_{rps}$ (word) EO (word)  \n",
       "0               1.006    13.089  \n",
       "1               1.003    11.130  \n",
       "2               1.084    11.096  \n",
       "3               1.081     9.231  \n",
       "4               1.000     7.098  \n",
       "5                 nan     8.818  \n",
       "6                 nan     6.515  \n",
       "7               1.017    11.500  \n",
       "8               1.011    10.357  \n",
       "9               1.119     9.859  \n",
       "10              1.103     8.233  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = \"No incremental results here\"\n",
    "if DO_INCREMENTAL_EVAL:\n",
    "    print all_incremental_results.keys()\n",
    "    # dummy results in non-joint tasks\n",
    "    all_incremental_results['test_037/epoch_6']['t_t_detection_t/>_interval'] = float('nan')\n",
    "    all_incremental_results['test_038/epoch_8']['t_t_detection_<rps_word'] = float('nan')\n",
    "    all_incremental_results['test_038/epoch_8_timings']['t_t_detection_<rps_word'] = float('nan')\n",
    "    \n",
    "    display = dict()\n",
    "    display['RNN joint task (+timing)'] = all_incremental_results['test_033/epoch_45_timings']\n",
    "    display['RNN joint task (complex) (+timing)'] = all_incremental_results['test_034/epoch_37_timings']\n",
    "    display['LSTM joint task (+timing)'] = all_incremental_results['test_035/epoch_6_timings']\n",
    "    display['LSTM joint task (complex) (+timing)'] = all_incremental_results['test_036/epoch_15_timings']\n",
    "    display['LSTM single uttseg task (+timing)'] = all_incremental_results['test_038/epoch_8_timings']\n",
    "    \n",
    "    display['RNN joint task'] = all_incremental_results['test_033/epoch_45']\n",
    "    display['RNN joint task (complex)'] = all_incremental_results['test_034/epoch_37']\n",
    "    display['LSTM joint task'] = all_incremental_results['test_035/epoch_6']\n",
    "    display['LSTM joint task (complex)'] = all_incremental_results['test_036/epoch_15']\n",
    "    display['LSTM single disfluency task'] = all_incremental_results['test_037/epoch_6']\n",
    "    display['LSTM single uttseg task'] = all_incremental_results['test_038/epoch_8']\n",
    "    \n",
    "    final = convert_to_latex(display, eval_level=['word'], inc=True, utt_seg=False,\n",
    "                             only_include=['t_t_detection_t/>_interval',\n",
    "                                           't_t_detection_<rps_word',\n",
    "                                           'edit_overhead_rel_word'])\n",
    "    #final = final.drop(final.columns[[-2]], axis=1)\n",
    "print \"Part of table 4. in the paper\"\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final output evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM: 033/epoch_45 RNN (joint task)\n",
      "timings False\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "timings True\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "SYSTEM: 034/epoch_37 RNN (complex tags) (joint task)\n",
      "timings False\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "timings True\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "SYSTEM: 035/epoch_6 LSTM (joint task)\n",
      "timings False\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "timings True\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "SYSTEM: 036/epoch_15 LSTM (complex tags) (joint task)\n",
      "timings False\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "timings True\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "SYSTEM: 037/epoch_6 LSTM (disf only)\n",
      "timings False\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= False\n",
      "word\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= False\n",
      "word\n",
      "timings True\n",
      "SYSTEM: 038/epoch_8 LSTM (uttseg only)\n",
      "timings False\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "timings True\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_partial_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_partial_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "word\n"
     ]
    }
   ],
   "source": [
    "# Get all the final output results, this can take 3 minutes per system\n",
    "VERBOSE = False\n",
    "all_results = {}\n",
    "all_error_dicts = {}\n",
    "for system, system_name in allsystemsfinal:\n",
    "    print \"SYSTEM:\", system, system_name\n",
    "    for timings_string in [\"\",\n",
    "                           \"_timings\"\n",
    "                          ]:  # without and with timings\n",
    "        print \"timings\", timings_string!=\"\"\n",
    "        if timings_string == \"_timings\" and \"disf only\" in system_name:\n",
    "            continue\n",
    "        hyp_dir = experiment_dir\n",
    "        for division, disf_file in zip([\"heldout\", \"test\"],disfluency_files):\n",
    "            #if division == \"heldout\":\n",
    "            #    continue\n",
    "            print \"*\" * 30, division, \"*\" * 30\n",
    "            IDs, timings, words, pos_tags, labels = get_tag_data_from_corpus_file(disf_file)\n",
    "            f = open(disf_file)\n",
    "            f.close()\n",
    "            gold_data = {} #map from the file name to the data\n",
    "            for dialogue,a,b,c,d in zip(IDs, timings, words, pos_tags, labels):\n",
    "                # if \"asr\" in division and not dialogue[:4] in good_asr: continue\n",
    "                d = rename_all_repairs_in_line_with_index(list(d))\n",
    "                gold_data[dialogue] = (a,b,c,d)\n",
    "\n",
    "            #the below does just the final output evaluation, assuming a final output file, faster\n",
    "            hyp_file = '{0}/{1}/swbd_disf_{2}{3}{4}_data_output_final.text'.format(\n",
    "                                                                            hyp_dir,\n",
    "                                                                            system,\n",
    "                                                                            division,\n",
    "                                                                            partial,\n",
    "                                                                            timings_string)\n",
    "\n",
    "            word = True  # world-level analyses\n",
    "            error = True # get an error analysis\n",
    "            results,speaker_rate_dict,error_analysis = final_output_disfluency_eval_from_file(\n",
    "                                                        hyp_file,\n",
    "                                                        gold_data,\n",
    "                                                        utt_eval=\"disf only\" not in system_name,\n",
    "                                                        error_analysis=error,\n",
    "                                                        word=word,\n",
    "                                                        interval=False,\n",
    "                                                        outputfilename=None\n",
    "                                                        )\n",
    "\n",
    "            #the below does incremental and final output in one, also outputting the final outputs\n",
    "            #derivable from the incremental output, takes quite a while\n",
    "            if VERBOSE:\n",
    "                for k,v in results.items():\n",
    "                    print k,v\n",
    "            r_key = division + \"_\" + system + timings_string\n",
    "            all_results[r_key] = deepcopy(results)\n",
    "            if \"heldout\" in division:\n",
    "                # only do the error analyses on the heldout data\n",
    "                e_key = division + \"_\" + system + timings_string\n",
    "                all_error_dicts[e_key] = deepcopy(error_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part of table 2 in the paper\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System (eval. method)</th>\n",
       "      <th>$F_{rps}$ (per word)</th>\n",
       "      <th>$F_{e}$ (per word)</th>\n",
       "      <th>$F_{uttSeg}$ (per word)</th>\n",
       "      <th>NIST SU (word)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM joint task (transcript)</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.685</td>\n",
       "      <td>64.639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM joint task (+timing) (transcript)</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.689</td>\n",
       "      <td>57.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM joint task (complex) (transcript)</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.697</td>\n",
       "      <td>61.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM joint task (complex) (+timing) (transcript)</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.700</td>\n",
       "      <td>56.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSTM single disfluency task (transcript)</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.914</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSTM single uttseg task (transcript)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.732</td>\n",
       "      <td>56.493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSTM single uttseg task (+timing) (transcript)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>50.511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RNN joint task (transcript)</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.629</td>\n",
       "      <td>73.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RNN joint task (+timing) (transcript)</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.629</td>\n",
       "      <td>68.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RNN joint task (complex) (transcript)</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.671</td>\n",
       "      <td>64.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RNN joint task (complex) (+timing) (transcript)</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.678</td>\n",
       "      <td>59.083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               System (eval. method) $F_{rps}$ (per word)  \\\n",
       "0                       LSTM joint task (transcript)                0.713   \n",
       "1             LSTM joint task (+timing) (transcript)                0.715   \n",
       "2             LSTM joint task (complex) (transcript)                0.642   \n",
       "3   LSTM joint task (complex) (+timing) (transcript)                0.652   \n",
       "4           LSTM single disfluency task (transcript)                0.713   \n",
       "5               LSTM single uttseg task (transcript)                0.000   \n",
       "6     LSTM single uttseg task (+timing) (transcript)                0.000   \n",
       "7                        RNN joint task (transcript)                0.674   \n",
       "8              RNN joint task (+timing) (transcript)                0.677   \n",
       "9              RNN joint task (complex) (transcript)                0.627   \n",
       "10   RNN joint task (complex) (+timing) (transcript)                0.632   \n",
       "\n",
       "   $F_{e}$ (per word) $F_{uttSeg}$ (per word) NIST SU (word)  \n",
       "0               0.838                   0.685         64.639  \n",
       "1               0.848                   0.689         57.413  \n",
       "2               0.909                   0.697         61.895  \n",
       "3               0.909                   0.700         56.987  \n",
       "4               0.914                     nan            nan  \n",
       "5               0.000                   0.732         56.493  \n",
       "6               0.000                   0.740         50.511  \n",
       "7               0.814                   0.629         73.432  \n",
       "8               0.819                   0.629         68.388  \n",
       "9               0.907                   0.671         64.213  \n",
       "10              0.907                   0.678         59.083  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display = dict()\n",
    "# fill in dummy values\n",
    "all_results['test_037/epoch_6']['f1_t/>_word'] = float('nan')\n",
    "all_results['test_037/epoch_6']['NIST_SU_word'] = float('nan')\n",
    "#all_results['test_037/epoch_6_timings']['f1_t/>_word'] = 0\n",
    "#all_results['test_037/epoch_6_timings']['NIST_SU_word'] = 1000\n",
    "\n",
    "display['RNN joint task (+timing)'] = all_results['test_033/epoch_45_timings']\n",
    "display['RNN joint task (complex) (+timing)'] = all_results['test_034/epoch_37_timings']\n",
    "display['LSTM joint task (+timing)'] = all_results['test_035/epoch_6_timings']\n",
    "display['LSTM joint task (complex) (+timing)'] = all_results['test_036/epoch_15_timings']\n",
    "display['LSTM single uttseg task (+timing)'] = all_results['test_038/epoch_8_timings']\n",
    "\n",
    "display['RNN joint task'] = all_results['test_033/epoch_45']\n",
    "display['RNN joint task (complex)'] = all_results['test_034/epoch_37']\n",
    "display['LSTM joint task'] = all_results['test_035/epoch_6']\n",
    "display['LSTM joint task (complex)'] = all_results['test_036/epoch_15']\n",
    "display['LSTM single disfluency task'] = all_results['test_037/epoch_6']\n",
    "display['LSTM single uttseg task'] = all_results['test_038/epoch_8']\n",
    "\n",
    "final = convert_to_latex(display, eval_level=['word'], inc=False, utt_seg=False,\n",
    "                         only_include=['f1_<rps_word',\n",
    "                                       'f1_<e_word',\n",
    "                                       'f1_t/>_word',\n",
    "                                       'NIST_SU_word'\n",
    "                                       \n",
    "                                      ])\n",
    "#final = final.drop(final.columns[[-2]], axis=1)\n",
    "print \"Part of table 2 in the paper\"\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint vs. single task comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part of table 2 in the paper\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System (eval. method)</th>\n",
       "      <th>$F_{rps}$ (per word)</th>\n",
       "      <th>$F_{e}$ (per word)</th>\n",
       "      <th>$F_{uttSeg}$ (per word)</th>\n",
       "      <th>NIST SU (word)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM joint task (transcript)</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.689</td>\n",
       "      <td>57.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM single disfluency task (transcript)</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.914</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM single task (transcript)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>50.511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      System (eval. method) $F_{rps}$ (per word)  \\\n",
       "0              LSTM joint task (transcript)                0.715   \n",
       "1  LSTM single disfluency task (transcript)                0.713   \n",
       "2             LSTM single task (transcript)                0.000   \n",
       "\n",
       "  $F_{e}$ (per word) $F_{uttSeg}$ (per word) NIST SU (word)  \n",
       "0              0.848                   0.689         57.413  \n",
       "1              0.914                     nan            nan  \n",
       "2              0.000                   0.740         50.511  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display = dict()\n",
    "# fill in dummy values\n",
    "\n",
    "display['LSTM single task'] = all_results['test_038/epoch_8_timings']\n",
    "display['LSTM joint task'] = all_results['test_035/epoch_6_timings']\n",
    "display['LSTM single disfluency task'] = all_results['test_037/epoch_6']\n",
    "\n",
    "\n",
    "final = convert_to_latex(display, eval_level=['word'], inc=False, utt_seg=False,\n",
    "                         only_include=['f1_<rps_word',\n",
    "                                       'f1_<e_word',\n",
    "                                       'f1_t/>_word',\n",
    "                                       'NIST_SU_word'\n",
    "                                       \n",
    "                                      ])\n",
    "#final = final.drop(final.columns[[-2]], axis=1)\n",
    "print \"Part of table 2 in the paper\"\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repair Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** heldout_035/epoch_6 <rps ******************************\n",
      "type ******************************\n",
      "del & (37/132) & 0.438\\\\\n",
      "rep & (846/1022) & 0.906\\\\\n",
      "sub & (647/1061) & 0.758\\\\\n",
      "0.690744920993\n",
      "len ******************************\n",
      "0 & (1/1) & 0.006\\\\\n",
      "1 & (992/1258) & 0.882\\\\\n",
      "2 & (342/531) & 0.784\\\\\n",
      "3 & (115/222) & 0.682\\\\\n",
      "4 & (48/106) & 0.623\\\\\n",
      "5 & (16/50) & 0.485\\\\\n",
      "6 & (10/25) & 0.571\\\\\n",
      "7 & (4/11) & 0.533\\\\\n",
      "8 & (2/6) & 0.500\\\\\n",
      "9 & (0/1) & 0.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/2) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.690744920993\n",
      "****************************** heldout_036/epoch_15 <rps ******************************\n",
      "type ******************************\n",
      "del & (21/132) & 0.271\\\\\n",
      "rep & (741/1022) & 0.829\\\\\n",
      "sub & (470/1061) & 0.563\\\\\n",
      "0.556207674944\n",
      "len ******************************\n",
      "0 & (0/1) & 0.000\\\\\n",
      "1 & (934/1258) & 0.811\\\\\n",
      "2 & (215/531) & 0.542\\\\\n",
      "3 & (48/222) & 0.348\\\\\n",
      "4 & (22/106) & 0.338\\\\\n",
      "5 & (8/50) & 0.276\\\\\n",
      "6 & (3/25) & 0.214\\\\\n",
      "7 & (1/11) & 0.154\\\\\n",
      "8 & (1/6) & 0.286\\\\\n",
      "9 & (0/1) & 0.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/2) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.556207674944\n",
      "****************************** heldout_036/epoch_15_timings <rps ******************************\n",
      "type ******************************\n",
      "del & (22/132) & 0.280\\\\\n",
      "rep & (752/1022) & 0.836\\\\\n",
      "sub & (491/1061) & 0.575\\\\\n",
      "0.571106094808\n",
      "len ******************************\n",
      "0 & (0/1) & 0.000\\\\\n",
      "1 & (949/1258) & 0.816\\\\\n",
      "2 & (224/531) & 0.551\\\\\n",
      "3 & (53/222) & 0.377\\\\\n",
      "4 & (25/106) & 0.379\\\\\n",
      "5 & (8/50) & 0.276\\\\\n",
      "6 & (3/25) & 0.214\\\\\n",
      "7 & (1/11) & 0.154\\\\\n",
      "8 & (2/6) & 0.500\\\\\n",
      "9 & (0/1) & 0.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/2) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.571106094808\n",
      "****************************** heldout_034/epoch_37 <rps ******************************\n",
      "type ******************************\n",
      "del & (19/132) & 0.250\\\\\n",
      "rep & (728/1022) & 0.818\\\\\n",
      "sub & (470/1061) & 0.552\\\\\n",
      "0.549435665914\n",
      "len ******************************\n",
      "0 & (1/1) & 1.000\\\\\n",
      "1 & (926/1258) & 0.801\\\\\n",
      "2 & (209/531) & 0.524\\\\\n",
      "3 & (49/222) & 0.343\\\\\n",
      "4 & (20/106) & 0.317\\\\\n",
      "5 & (8/50) & 0.276\\\\\n",
      "6 & (3/25) & 0.207\\\\\n",
      "7 & (0/11) & 0.000\\\\\n",
      "8 & (1/6) & 0.286\\\\\n",
      "9 & (0/1) & 0.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/2) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.549435665914\n",
      "****************************** heldout_034/epoch_37_timings <rps ******************************\n",
      "type ******************************\n",
      "del & (21/132) & 0.271\\\\\n",
      "rep & (737/1022) & 0.823\\\\\n",
      "sub & (500/1061) & 0.570\\\\\n",
      "0.567945823928\n",
      "len ******************************\n",
      "0 & (1/1) & 1.000\\\\\n",
      "1 & (953/1258) & 0.811\\\\\n",
      "2 & (214/531) & 0.526\\\\\n",
      "3 & (51/222) & 0.352\\\\\n",
      "4 & (24/106) & 0.366\\\\\n",
      "5 & (10/50) & 0.333\\\\\n",
      "6 & (3/25) & 0.207\\\\\n",
      "7 & (1/11) & 0.167\\\\\n",
      "8 & (1/6) & 0.286\\\\\n",
      "9 & (0/1) & 0.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/2) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.567945823928\n",
      "****************************** heldout_035/epoch_6_timings <rps ******************************\n",
      "type ******************************\n",
      "del & (40/132) & 0.465\\\\\n",
      "rep & (852/1022) & 0.909\\\\\n",
      "sub & (689/1061) & 0.787\\\\\n",
      "0.713769751693\n",
      "len ******************************\n",
      "0 & (1/1) & 0.005\\\\\n",
      "1 & (1010/1258) & 0.891\\\\\n",
      "2 & (359/531) & 0.807\\\\\n",
      "3 & (124/222) & 0.717\\\\\n",
      "4 & (53/106) & 0.667\\\\\n",
      "5 & (18/50) & 0.529\\\\\n",
      "6 & (10/25) & 0.571\\\\\n",
      "7 & (4/11) & 0.533\\\\\n",
      "8 & (2/6) & 0.500\\\\\n",
      "9 & (0/1) & 0.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/2) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.713769751693\n",
      "****************************** heldout_037/epoch_6 <rps ******************************\n",
      "type ******************************\n",
      "del & (46/132) & 0.517\\\\\n",
      "rep & (881/1022) & 0.926\\\\\n",
      "sub & (668/1061) & 0.773\\\\\n",
      "0.720090293454\n",
      "len ******************************\n",
      "0 & (0/1) & 0.000\\\\\n",
      "1 & (1028/1258) & 0.899\\\\\n",
      "2 & (359/531) & 0.807\\\\\n",
      "3 & (114/222) & 0.679\\\\\n",
      "4 & (56/106) & 0.691\\\\\n",
      "5 & (22/50) & 0.611\\\\\n",
      "6 & (9/25) & 0.529\\\\\n",
      "7 & (5/11) & 0.625\\\\\n",
      "8 & (2/6) & 0.500\\\\\n",
      "9 & (0/1) & 0.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/2) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.720090293454\n",
      "****************************** heldout_033/epoch_45 <rps ******************************\n",
      "type ******************************\n",
      "del & (25/132) & 0.318\\\\\n",
      "rep & (798/1022) & 0.877\\\\\n",
      "sub & (588/1061) & 0.713\\\\\n",
      "0.637020316027\n",
      "len ******************************\n",
      "0 & (0/1) & 0.000\\\\\n",
      "1 & (926/1258) & 0.848\\\\\n",
      "2 & (315/531) & 0.745\\\\\n",
      "3 & (101/222) & 0.625\\\\\n",
      "4 & (41/106) & 0.558\\\\\n",
      "5 & (15/50) & 0.462\\\\\n",
      "6 & (8/25) & 0.485\\\\\n",
      "7 & (4/11) & 0.533\\\\\n",
      "8 & (1/6) & 0.286\\\\\n",
      "9 & (0/1) & 0.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/2) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.637020316027\n",
      "****************************** heldout_038/epoch_8 <rps ******************************\n",
      "type ******************************\n",
      "del & (0/132) & 0.000\\\\\n",
      "rep & (0/1022) & 0.000\\\\\n",
      "sub & (0/1061) & 0.000\\\\\n",
      "0.0\n",
      "len ******************************\n",
      "0 & (0/1) & 0.000\\\\\n",
      "1 & (0/1258) & 0.000\\\\\n",
      "2 & (0/531) & 0.000\\\\\n",
      "3 & (0/222) & 0.000\\\\\n",
      "4 & (0/106) & 0.000\\\\\n",
      "5 & (0/50) & 0.000\\\\\n",
      "6 & (0/25) & 0.000\\\\\n",
      "7 & (0/11) & 0.000\\\\\n",
      "8 & (0/6) & 0.000\\\\\n",
      "9 & (0/1) & 0.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/2) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.0\n",
      "****************************** heldout_033/epoch_45_timings <rps ******************************\n",
      "type ******************************\n",
      "del & (28/132) & 0.350\\\\\n",
      "rep & (806/1022) & 0.882\\\\\n",
      "sub & (610/1061) & 0.730\\\\\n",
      "0.651918735892\n",
      "len ******************************\n",
      "0 & (0/1) & 0.000\\\\\n",
      "1 & (947/1258) & 0.859\\\\\n",
      "2 & (324/531) & 0.758\\\\\n",
      "3 & (103/222) & 0.634\\\\\n",
      "4 & (42/106) & 0.568\\\\\n",
      "5 & (15/50) & 0.462\\\\\n",
      "6 & (8/25) & 0.485\\\\\n",
      "7 & (4/11) & 0.533\\\\\n",
      "8 & (1/6) & 0.286\\\\\n",
      "9 & (0/1) & 0.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/2) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.651918735892\n",
      "****************************** heldout_038/epoch_8_timings <rps ******************************\n",
      "type ******************************\n",
      "del & (0/132) & 0.000\\\\\n",
      "rep & (0/1022) & 0.000\\\\\n",
      "sub & (0/1061) & 0.000\\\\\n",
      "0.0\n",
      "len ******************************\n",
      "0 & (0/1) & 0.000\\\\\n",
      "1 & (0/1258) & 0.000\\\\\n",
      "2 & (0/531) & 0.000\\\\\n",
      "3 & (0/222) & 0.000\\\\\n",
      "4 & (0/106) & 0.000\\\\\n",
      "5 & (0/50) & 0.000\\\\\n",
      "6 & (0/25) & 0.000\\\\\n",
      "7 & (0/11) & 0.000\\\\\n",
      "8 & (0/6) & 0.000\\\\\n",
      "9 & (0/1) & 0.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/2) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# rps and rms errors\n",
    "#Error analyses on exact match ('rms') and getting the right repair start ('rps')\n",
    "target_tags = ['<rps']\n",
    "\n",
    "for div,all_error in all_error_dicts.items():\n",
    "    # print div, type(all_error)\n",
    "   \n",
    "    if type(all_error) == bool: continue\n",
    "    if \"test\" in div: continue\n",
    "    #if not 'TTO only' in div or \"asr\" in div: continue\n",
    "    for tag, errors in all_error.items():\n",
    "        if tag not in target_tags:\n",
    "            continue\n",
    "        print \"*\" * 30, div, tag, \"*\" * 30\n",
    "        # print errors\n",
    "        # continue\n",
    "        #if not 'TTO only' in div or \"asr\" in div: continue\n",
    "        error = {\"TP\" : {}, \"FP\" : {}, \"FN\": {} }\n",
    "        for k,v in errors.items():\n",
    "            #if k == \"FP\":\n",
    "            #    continue\n",
    "            # print k, len(v)\n",
    "            typedict = defaultdict(int)\n",
    "            lendict = defaultdict(int)\n",
    "            for repair in v:\n",
    "\n",
    "                #print repair.gold_context\n",
    "                onset = \"\"\n",
    "                if tag == \"<rps\" or tag == \"<rms\":\n",
    "                    \n",
    "                    \n",
    "                    for i in range(0,len(repair.gold_context)):\n",
    "                        if repair.gold_context[i] == \"+|+\":\n",
    "                            onset = repair.gold_context[i+1]\n",
    "                            break\n",
    "\n",
    "                    word = onset.split(\"|\")[0]\n",
    "                    #if k == \"FP\":\n",
    "                    #    onset = gold_onset\n",
    "                    if \"<e\" in onset and not tag == \"<e\":\n",
    "                        typedict[\"<e\"]+=1\n",
    "                    else:\n",
    "                        if word in [\"and\",\"or\",\"but\",\"so\",\"because\",\"that\",\"although\"]:\n",
    "                            typedict[\"CC\"]+=1\n",
    "                        elif word in [\"i\",\"we\",\"they\",\"im\",\"ive\",\"he\",\"she\",\"id\"]:\n",
    "                            typedict[\"subj\"]+=1\n",
    "                        elif word in [\"you\",\"the\"] or \"$\" in word:\n",
    "                            typedict[\"proper_other\"]+=1\n",
    "                        elif word in [\"yeah\",\"no\",\"okay\",\"yes\",\"right\",\"uh-huh\"]:\n",
    "                            typedict[\"ack\"]+=1\n",
    "                        elif word in [\"it\",\"its\"]:\n",
    "                            typedict[\"it\"]+=1\n",
    "                        else:\n",
    "                            typedict[word]+=1\n",
    "                \n",
    "                if tag == \"<rps\" or tag == \"<rms\": # and not k == 'FP':\n",
    "                    if k == \"TP\" and len(repair.reparandumWords) > 8:\n",
    "                        # should not be getting any over 8 words\n",
    "                        print \"** overlength repair!\"\n",
    "                        print repair\n",
    "                    lendict[len(repair.reparandumWords) + len(repair.interregnumWords)]+=1\n",
    "                    repair_type = None\n",
    "                    if repair.type:\n",
    "                        repair_type = repair.type \n",
    "                        typedict[repair_type]+=1\n",
    "\n",
    "            error[k]['len'] = deepcopy(lendict)\n",
    "            error[k]['type'] = deepcopy(typedict)\n",
    "\n",
    "                \n",
    "        for mode in ['type', 'len']:\n",
    "            #q1. THE RECALL RATES FOR VARIOUS GOLD REPAIR TYPES\n",
    "            print mode, \"*\" * 30\n",
    "            tps = error['TP'][mode]\n",
    "            fns = error['FN'][mode]\n",
    "            fps = error['FP'][mode]\n",
    "\n",
    "            total_tps = 0\n",
    "            total_fns = 0\n",
    "            total_fps = 0\n",
    "            top_n = 50\n",
    "            all_items = list(set(tps.keys() + fns.keys()))\n",
    "            # print all_items\n",
    "            for k in sorted(all_items,  reverse=False):\n",
    "                #print k, \"*\" * 30\n",
    "                if mode == 'type' and k not in [\"rep\", \"del\", \"sub\"]:\n",
    "                    continue\n",
    "                recall_total = tps[k] + fns[k]\n",
    "                recall = 0 if tps[k] == 0 else tps[k]/recall_total\n",
    "                precision_total = tps[k] + fps[k]\n",
    "                precision = 0 if tps[k] == 0 else tps[k]/precision_total\n",
    "                fscore = 0 if precision == 0 or recall == 0 else (2 * (precision * recall))/(precision + recall)\n",
    "                # print k, ':', tps[k], \"out of\", recall_total\n",
    "                #print k, ':', tps[k], \"out of\", precision_total\n",
    "                total_tps += tps[k]\n",
    "                total_fns += fns[k]\n",
    "                total_fps += fps[k]\n",
    "                print \" & \".join([str(k), \"({0}/{1})\".format(tps[k],recall_total), \n",
    "                                  '{0:.3f}'.format(fscore)]) + \"\\\\\\\\\"\n",
    "                top_n-=1\n",
    "                if top_n <= 0:\n",
    "                    break\n",
    "            print total_tps/(total_fns + total_tps)\n",
    "\n",
    "            if False:\n",
    "                #q2. ERROR TYPE SUMMARY\n",
    "                print \"*\" * 30\n",
    "                total = sum(fns.values()+tps.values())\n",
    "\n",
    "                errormass = 0\n",
    "                errortotal = 0\n",
    "                top_n = 20\n",
    "                for k,v in sorted(tps.items(),key= lambda x: x[1],reverse=True):\n",
    "                    print k,\"&\",v,\"&\",'{0:.2f}'.format(v/total)\n",
    "                    errormass +=(v/total * 100)\n",
    "                    errortotal+=v\n",
    "                    top_n-=1\n",
    "                    if top_n <= 0: break\n",
    "                print \"total &\",errortotal,\"&\",'{0:.2f}'.format(errormass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utterance Segmentation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heldout_035/epoch_6 <type 'dict'>\n",
      "heldout_035/epoch_6 <rps\n",
      "heldout_035/epoch_6 <rms\n",
      "heldout_035/epoch_6 <e\n",
      "heldout_035/epoch_6 t/>\n",
      "\n",
      "FP 2065\n",
      "\n",
      "TP 3865\n",
      "\n",
      "FN 1783\n",
      "heldout_035/epoch_6_timings <type 'dict'>\n",
      "heldout_035/epoch_6_timings <rps\n",
      "heldout_035/epoch_6_timings <rms\n",
      "heldout_035/epoch_6_timings <e\n",
      "heldout_035/epoch_6_timings t/>\n",
      "\n",
      "FP 1276\n",
      "\n",
      "TP 3442\n",
      "\n",
      "FN 2206\n",
      "defaultdict(<type 'int'>, {})\n",
      "defaultdict(<type 'int'>, {})\n",
      "ack & 571 & 10.11\n",
      "CC & 485 & 8.59\n",
      "<e & 223 & 3.95\n",
      "<rps & 199 & 3.52\n",
      "subj & 191 & 3.38\n",
      " & 54 & 0.96\n",
      "proper_other & 52 & 0.92\n",
      "it & 44 & 0.78\n",
      "if & 16 & 0.28\n",
      "what & 14 & 0.25\n",
      "my & 13 & 0.23\n",
      "a & 12 & 0.21\n",
      "thats & 11 & 0.19\n",
      "do & 10 & 0.18\n",
      "in & 10 & 0.18\n",
      "when & 10 & 0.18\n",
      "there & 9 & 0.16\n",
      "sure & 8 & 0.14\n",
      "maybe & 8 & 0.14\n",
      "at & 8 & 0.14\n",
      "theyre & 7 & 0.12\n",
      "really & 7 & 0.12\n",
      "is & 7 & 0.12\n",
      "then & 6 & 0.11\n",
      "yep & 5 & 0.09\n",
      "actually & 5 & 0.09\n",
      "to & 5 & 0.09\n",
      "people & 5 & 0.09\n",
      "for & 5 & 0.09\n",
      "how & 5 & 0.09\n",
      "of & 5 & 0.09\n",
      "theres & 5 & 0.09\n",
      "th- & 5 & 0.09\n",
      "now & 4 & 0.07\n",
      "where & 4 & 0.07\n",
      "even & 4 & 0.07\n",
      "probably & 4 & 0.07\n",
      "this & 4 & 0.07\n",
      "a- & 4 & 0.07\n",
      "pretty & 3 & 0.05\n",
      "not & 3 & 0.05\n",
      "like & 3 & 0.05\n",
      "w- & 3 & 0.05\n",
      "are & 3 & 0.05\n",
      "on & 3 & 0.05\n",
      "about & 3 & 0.05\n",
      "whats & 3 & 0.05\n",
      "both & 3 & 0.05\n",
      "were & 3 & 0.05\n",
      "as & 3 & 0.05\n",
      "things & 3 & 0.05\n",
      "all & 2 & 0.04\n",
      "particularly & 2 & 0.04\n",
      "go & 2 & 0.04\n",
      "lets & 2 & 0.04\n",
      "somebody & 2 & 0.04\n",
      "every & 2 & 0.04\n",
      "who & 2 & 0.04\n",
      "was & 2 & 0.04\n",
      "sort & 2 & 0.04\n",
      "with & 2 & 0.04\n",
      "up & 2 & 0.04\n",
      "say & 2 & 0.04\n",
      "something & 2 & 0.04\n",
      "have & 2 & 0.04\n",
      "an- & 2 & 0.04\n",
      "after & 2 & 0.04\n",
      "most & 2 & 0.04\n",
      "especially & 2 & 0.04\n",
      "sometimes & 2 & 0.04\n",
      "d- & 1 & 0.02\n",
      "just & 1 & 0.02\n",
      "unemployment & 1 & 0.02\n",
      "being & 1 & 0.02\n",
      "sleep & 1 & 0.02\n",
      "pardon & 1 & 0.02\n",
      "wed & 1 & 0.02\n",
      "late & 1 & 0.02\n",
      "weve & 1 & 0.02\n",
      "big & 1 & 0.02\n",
      "television & 1 & 0.02\n",
      "possibly & 1 & 0.02\n",
      "ones & 1 & 0.02\n",
      "course & 1 & 0.02\n",
      "schools & 1 & 0.02\n",
      "taxes & 1 & 0.02\n",
      "leave & 1 & 0.02\n",
      "did & 1 & 0.02\n",
      "bad & 1 & 0.02\n",
      "t- & 1 & 0.02\n",
      "either & 1 & 0.02\n",
      "went & 1 & 0.02\n",
      "someday & 1 & 0.02\n",
      "absolutely & 1 & 0.02\n",
      "bu- & 1 & 0.02\n",
      "some & 1 & 0.02\n",
      "back & 1 & 0.02\n",
      "belie- & 1 & 0.02\n",
      "p- & 1 & 0.02\n",
      "our & 1 & 0.02\n",
      "insurance & 1 & 0.02\n",
      "heres & 1 & 0.02\n",
      "ac- & 1 & 0.02\n",
      "goes & 1 & 0.02\n",
      "co- & 1 & 0.02\n",
      "e- & 1 & 0.02\n",
      "be & 1 & 0.02\n",
      "never & 1 & 0.02\n",
      "here & 1 & 0.02\n",
      "let & 1 & 0.02\n",
      "plea & 1 & 0.02\n",
      "put & 1 & 0.02\n",
      "by & 1 & 0.02\n",
      "service & 1 & 0.02\n",
      "teachers & 1 & 0.02\n",
      "ill & 1 & 0.02\n",
      "arent & 1 & 0.02\n",
      "youve & 1 & 0.02\n",
      "wha- & 1 & 0.02\n",
      "dont & 1 & 0.02\n",
      "youd & 1 & 0.02\n",
      "doesnt & 1 & 0.02\n",
      "another & 1 & 0.02\n",
      "theyd & 1 & 0.02\n",
      "drove & 1 & 0.02\n",
      "guess & 1 & 0.02\n",
      "from & 1 & 0.02\n",
      "would & 1 & 0.02\n",
      "tell & 1 & 0.02\n",
      "selling & 1 & 0.02\n",
      "fire & 1 & 0.02\n",
      "nobody & 1 & 0.02\n",
      "gas & 1 & 0.02\n",
      "those & 1 & 0.02\n",
      "n- & 1 & 0.02\n",
      "kind & 1 & 0.02\n",
      "theyve & 1 & 0.02\n",
      "shes & 1 & 0.02\n",
      "while & 1 & 0.02\n",
      "supposed & 1 & 0.02\n",
      "cab & 1 & 0.02\n",
      "didnt & 1 & 0.02\n",
      "called & 1 & 0.02\n",
      "woman & 1 & 0.02\n",
      "any & 1 & 0.02\n",
      "again & 1 & 0.02\n",
      "wel- & 1 & 0.02\n",
      "same & 1 & 0.02\n",
      "other & 1 & 0.02\n",
      "which & 1 & 0.02\n",
      "higher & 1 & 0.02\n",
      "o- & 1 & 0.02\n",
      "i- & 1 & 0.02\n",
      "nothing & 1 & 0.02\n",
      "give & 1 & 0.02\n",
      "definitely & 1 & 0.02\n",
      "first & 1 & 0.02\n",
      "once & 1 & 0.02\n",
      "******************************\n",
      "total & 2206 & 39.06\n"
     ]
    }
   ],
   "source": [
    "#Error analyses\n",
    "error = {\"TP\" : {}, \"FP\" : {}, \"FN\": {} }\n",
    " \n",
    "for div,all_error in all_error_dicts.items():\n",
    "    if not \"35\" in div:\n",
    "        continue\n",
    "    print div, type(all_error)\n",
    "    if type(all_error) == bool: continue\n",
    "    if \"test\" in div: continue\n",
    "    #if not 'TTO only' in div or \"asr\" in div: continue\n",
    "    for tag,errors in all_error.items():\n",
    "        print div, tag\n",
    "        #if not 'TTO only' in div or \"asr\" in div: continue\n",
    "        if not tag == \"t/>\": continue\n",
    "        for k,v in errors.items():\n",
    "    \n",
    "            print \"\"\n",
    "            #if k == \"FP\": continue\n",
    "            print k, len(v)\n",
    "            typedict = defaultdict(int)\n",
    "            lendict = defaultdict(int)\n",
    "            #print v[0]\n",
    "            for repair in v:\n",
    "                #if len(repair)==0: continue\n",
    "                #print \"*\"\n",
    "                #print repair\n",
    "                #print repair.gold_context\n",
    "                onset = \"\"\n",
    "                if tag == \"<rps\":\n",
    "                    \n",
    "                    for i in rcange(0,len(repair.gold_context)):\n",
    "                        if repair.gold_context[i] == \"+|+\":\n",
    "                            onset = repair.gold_context[i+1]\n",
    "                            break\n",
    "                else:\n",
    "                    gold_onset = \"\"\n",
    "                    onset = \"\"\n",
    "                    word = \"\"\n",
    "                    if len(repair.gold_tags_right_context)>1:\n",
    "                        gold_onset = repair.gold_tags_right_context[1]\n",
    "                        onset = repair.tags_right_context[1]\n",
    "                        word = repair.words_right_context[1]\n",
    "                    #penult = repair.tags_left_context[-1]\n",
    "                    #print repair\n",
    "                    if k == \"FP\":\n",
    "                        onset = gold_onset\n",
    "                    if \"<rps\" in onset:\n",
    "                        typedict[\"<rps\"]+=1\n",
    "                    elif \"<e\" in onset:\n",
    "                        typedict[\"<e\"]+=1\n",
    "                    else:\n",
    "                        if word in [\"and\",\"or\",\"but\",\"so\",\"because\",\"that\",\"although\"]:\n",
    "                            typedict[\"CC\"]+=1\n",
    "                        elif word in [\"i\",\"we\",\"they\",\"im\",\"ive\",\"he\",\"she\",\"id\"]:\n",
    "                            typedict[\"subj\"]+=1\n",
    "                        elif word in [\"you\",\"the\"] or \"$\" in word:\n",
    "                            typedict[\"proper_other\"]+=1\n",
    "                        elif word in [\"yeah\",\"no\",\"okay\",\"yes\",\"right\",\"uh-huh\"]:\n",
    "                            typedict[\"ack\"]+=1\n",
    "                        elif word in [\"it\",\"its\"]:\n",
    "                            typedict[\"it\"]+=1\n",
    "                        else:\n",
    "                            typedict[word]+=1\n",
    "                         \n",
    "                \n",
    "                #if \"<t\" in repair.gold_context\n",
    "                #for t in [\"tt\",\"cc\",\"ct\",\"tc\"]:\n",
    "                #    if \"<\" + t + \">\" in onset:\n",
    "                #        typedict[t]+=1\n",
    "                #        if not t[0]=='t':\n",
    "                #            print repair\n",
    "                if tag == \"<rps\" and not k == 'FP':\n",
    "                    lendict[repair.type]+=1\n",
    "                error[k]['len'] = deepcopy(lendict)\n",
    "                error[k]['type'] = deepcopy(typedict)\n",
    "\n",
    "#tp = deepcopy(lendict)\n",
    "#q1. THE RECALL RATES FOR VARIOUS GOLD REPAIRS\n",
    "tp = error['TP']['len']\n",
    "print tp\n",
    "print error['FN']['len']\n",
    "for k,v in sorted(error['FN']['len'].items()):\n",
    "    print \" & \".join([k, \"({0})\".format(v + tp[k]), \n",
    "                      '{0:.1f}'.format(100 * float(tp[k])/float(v+ tp[k]))]) + \"\\\\\\\\\"\n",
    "\n",
    "tps = error['TP']['type']\n",
    "fns = error['FN']['type']\n",
    "fps = error['FP']['type']\n",
    "\n",
    "total = sum(fns.values()+tps.values())\n",
    "\n",
    "errormass = 0\n",
    "errortotal = 0\n",
    "for k,v in sorted(fns.items(),key= lambda x: x[1],reverse=True):\n",
    "    print k,\"&\",v,\"&\",'{0:.2f}'.format(v/total * 100)\n",
    "    errormass +=(v/total * 100)\n",
    "    errortotal+=v\n",
    "print \"*\" * 30\n",
    "print \"total &\",errortotal,\"&\",'{0:.2f}'.format(errormass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " #TODO for paper/future\n",
    "# - check WER for ASR results and exclude those with high ones given they might have high overlap :(\n",
    "# - need to adjust the time to detection scores based on the time it comes in from Increco?? \n",
    "#      Also for ttdetection can only use word ends unless we re-do the mapping- just needs explanation\n",
    "# - delayed accuracy based on time, or not bother? do moving window instead and plot this over time- average moving window accuracy\n",
    "# - error analysis plots\n",
    "# 036- full task with LSTM- should improve massively over 034, which also needs re-running\n",
    "# Reproduce 027 (with full training data, efficiently) and re-run with LSTM- not much time.\n",
    "#Q2 TODO the extent to which the network is memorizing- need to plug these in with the repair gold standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
