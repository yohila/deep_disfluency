{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "# add the deep_disfluency module to the path\n",
    "sys.path.append(\"../../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from deep_disfluency.evaluation.disf_evaluation import incremental_output_disfluency_eval_from_file\n",
    "from deep_disfluency.evaluation.disf_evaluation import final_output_disfluency_eval_from_file\n",
    "from deep_disfluency.evaluation.eval_utils import get_tag_data_from_corpus_file\n",
    "from deep_disfluency.evaluation.eval_utils import rename_all_repairs_in_line_with_index\n",
    "from deep_disfluency.evaluation.eval_utils import sort_into_dialogue_speakers\n",
    "from deep_disfluency.evaluation.results_utils import convert_to_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the locations of all needed files\n",
    "# Assume we have the incremental output\n",
    "experiment_dir = \"../../../experiments\"\n",
    "\n",
    "partial_words = False  # No partial words in these experiments, removed\n",
    "if partial_words:\n",
    "    partial = '_partial'\n",
    "else:\n",
    "    partial = ''\n",
    "#the evaluation files (as text files)\n",
    "disf_dir = \"../../../data/disfluency_detection/switchboard\"\n",
    "disfluency_files = [\n",
    "                    disf_dir + \"/swbd_disf_heldout{}_data_timings.csv\".format(partial),\n",
    "                    disf_dir + \"/swbd_disf_test{}_data_timings.csv\".format(partial)\n",
    "                   ]\n",
    "    \n",
    "\n",
    "allsystemsfinal = [\"021/epoch_40\",\n",
    "                   \"041/epoch_16\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "021/epoch_40\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julian/.local/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing final output to file ../../../experiments/021/epoch_40/swbd_disf_heldout_data_output_final.text\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "writing final output to file ../../../experiments/021/epoch_40/swbd_disf_test_data_output_final.text\n",
      "041/epoch_16\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "writing final output to file ../../../experiments/041/epoch_16/swbd_disf_heldout_data_output_final.text\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "writing final output to file ../../../experiments/041/epoch_16/swbd_disf_test_data_output_final.text\n"
     ]
    }
   ],
   "source": [
    "# create final output files for the final output evaluation (and do incremental evaluation first:\n",
    "DO_INCREMENTAL_EVAL = True\n",
    "VERBOSE = False\n",
    "if DO_INCREMENTAL_EVAL:\n",
    "    all_incremental_results = {}\n",
    "    all_incremental_error_dicts = {}\n",
    "    for system in allsystemsfinal:\n",
    "        print system\n",
    "        #if 'complex' in system: break\n",
    "        hyp_dir = experiment_dir + \"/\" + system\n",
    "        #hyp_dir = experiment_dir\n",
    "        for division, disf_file in zip([\"heldout\",\"test\"], disfluency_files):\n",
    "            print \"*\" * 30, division, \"*\" * 30\n",
    "            IDs, timings, words, pos_tags, labels = get_tag_data_from_corpus_file(disf_file)\n",
    "            gold_data = {} #map from the file name to the data\n",
    "            for dialogue,a,b,c,d in zip(IDs, timings, words, pos_tags, labels):\n",
    "                # if \"asr\" in division and not dialogue[:4] in good_asr: continue\n",
    "                gold_data[dialogue] = (a,b,c,d)\n",
    "            inc_filename = hyp_dir + \"/swbd_disf_{0}{1}_data_output_increco\".format(division, partial) + \".text\"\n",
    "            final_output_name = inc_filename.replace(\"_increco\", \"_final\")\n",
    "            results, error_analysis = incremental_output_disfluency_eval_from_file(\n",
    "                                                                             inc_filename,\n",
    "                                                                             gold_data,\n",
    "                                                                             utt_eval=True,\n",
    "                                                                             error_analysis=True,\n",
    "                                                                             word=True,\n",
    "                                                                             interval=False,\n",
    "                                                                             outputfilename=final_output_name)\n",
    "            if VERBOSE:\n",
    "                for k,v in results.items():\n",
    "                    print k,v\n",
    "            all_incremental_results[division + \"_\" + system] = deepcopy(results)\n",
    "            if \"heldout\" in division:\n",
    "                # only do the error analyses on the heldout data\n",
    "                all_incremental_error_dicts[division + \"_\" + system] = deepcopy(error_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System (eval. method)</th>\n",
       "      <th>TTD$_{rms}$ (word)</th>\n",
       "      <th>TTD$_{rps}$ (word)</th>\n",
       "      <th>EO (word)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM (window length=2) (+ POS) (transcript)</td>\n",
       "      <td>2.455</td>\n",
       "      <td>1.118</td>\n",
       "      <td>4.293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RNN (window length=2) (+ POS) (transcript)</td>\n",
       "      <td>2.484</td>\n",
       "      <td>1.117</td>\n",
       "      <td>4.832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         System (eval. method) TTD$_{rms}$ (word)  \\\n",
       "0  LSTM (window length=2) (+ POS) (transcript)              2.455   \n",
       "1   RNN (window length=2) (+ POS) (transcript)              2.484   \n",
       "\n",
       "  TTD$_{rps}$ (word) EO (word)  \n",
       "0              1.118     4.293  \n",
       "1              1.117     4.832  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = \"No incremental results here\"\n",
    "if DO_INCREMENTAL_EVAL:\n",
    "    display_results = dict()\n",
    "    display_results['RNN (window length=2) (+ POS)'] = all_incremental_results['test_021/epoch_40']\n",
    "    display_results['LSTM (window length=2) (+ POS)'] = all_incremental_results['test_041/epoch_16']\n",
    "    final = convert_to_latex(display_results, eval_level=['word'], inc=True, utt_seg=False, only_include=\n",
    "                            ['t_t_detection_<rms_word', 't_t_detection_<rps_word', 'edit_overhead_rel_word'])\n",
    "    #final = final.drop(final.columns[[-2]], axis=1)\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final output evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "021/epoch_40\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= False\n",
      "word\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= False\n",
      "word\n",
      "041/epoch_16\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= False\n",
      "word\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= False\n",
      "word\n"
     ]
    }
   ],
   "source": [
    "all_results = {}\n",
    "all_error_dicts = {}\n",
    "VERBOSE = False\n",
    "for system in allsystemsfinal:\n",
    "    print system\n",
    "    #if 'complex' in system: break\n",
    "    hyp_dir = experiment_dir\n",
    "    for division, disf_file in zip([\"heldout\", \"test\"],disfluency_files):\n",
    "        #if not division == \"heldout\": continue\n",
    "        print \"*\" * 30, division, \"*\" * 30\n",
    "        IDs, timings, words, pos_tags, labels = get_tag_data_from_corpus_file(disf_file)\n",
    "        gold_data = {} #map from the file name to the data\n",
    "        for dialogue,a,b,c,d in zip(IDs, timings, words, pos_tags, labels):\n",
    "            # if \"asr\" in division and not dialogue[:4] in good_asr: continue\n",
    "            d = rename_all_repairs_in_line_with_index(list(d))\n",
    "            gold_data[dialogue] = (a,b,c,d)\n",
    "\n",
    "        #the below does just the final output evaluation, assuming a final output file, faster\n",
    "        hyp_file = hyp_dir + '/' + system + \"/\" + \"swbd_disf_{0}{1}_data_output_final.text\".format(division,\n",
    "                                                                                                        partial)\n",
    "        word = True  # world-level analyses\n",
    "        error = True # get an error analysis\n",
    "        results,speaker_rate_dict,error_analysis = final_output_disfluency_eval_from_file(\n",
    "                                                        hyp_file,\n",
    "                                                        gold_data,\n",
    "                                                        utt_eval=False,\n",
    "                                                        error_analysis=error,\n",
    "                                                        word=word,\n",
    "                                                        interval=False,\n",
    "                                                        outputfilename=None\n",
    "                                                    )\n",
    "        #the below does incremental and final output in one, also outputting the final outputs\n",
    "        #derivable from the incremental output, takes quite a while\n",
    "        if VERBOSE:\n",
    "            for k,v in results.items():\n",
    "                print k,v\n",
    "        all_results[division + \"_\" + system] = deepcopy(results)\n",
    "        if \"heldout\" in division:\n",
    "            # only do the error analyses on the heldout data\n",
    "            all_error_dicts[division + \"_\" + system] = deepcopy(error_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['heldout_041/epoch_16', 'heldout_021/epoch_40', 'test_021/epoch_40', 'test_041/epoch_16']\n"
     ]
    }
   ],
   "source": [
    "print all_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System (eval. method)</th>\n",
       "      <th>$F_{rm}$ (per word)</th>\n",
       "      <th>$F_{rps}$ (per word)</th>\n",
       "      <th>$F_{e}$ (per word)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM (window length=2) (+ POS) (transcript)</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RNN (window length=2) (+ POS) (transcript)</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         System (eval. method) $F_{rm}$ (per word)  \\\n",
       "0  LSTM (window length=2) (+ POS) (transcript)               0.663   \n",
       "1   RNN (window length=2) (+ POS) (transcript)               0.665   \n",
       "\n",
       "  $F_{rps}$ (per word) $F_{e}$ (per word)  \n",
       "0                0.750              0.885  \n",
       "1                0.742              0.852  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_results = dict()\n",
    "display_results['RNN (window length=2) (+ POS)'] = all_results['test_021/epoch_40']\n",
    "display_results['LSTM (window length=2) (+ POS)'] = all_results['test_041/epoch_16']\n",
    "final = convert_to_latex(display_results, eval_level=['word'], inc=False, utt_seg=False, only_include=\n",
    "                        ['f1_<rm_word', 'f1_<rps_word', 'f1_<e_word'])\n",
    "#final = final.drop(final.columns[[-2]], axis=1)\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** heldout_041/epoch_16 <rps ******************************\n",
      "FP 219\n",
      "TP 1365\n",
      "FN 581\n",
      "type ******************************\n",
      "del & (26/101) & 0.391\\\\\n",
      "rep & (868/1001) & 0.920\\\\\n",
      "sub & (471/844) & 0.629\\\\\n",
      "0.701438848921\n",
      "len ******************************\n",
      "0 & (0/1) & 0.000\\\\\n",
      "1 & (901/1096) & 0.863\\\\\n",
      "2 & (307/467) & 0.724\\\\\n",
      "3 & (92/205) & 0.566\\\\\n",
      "4 & (37/88) & 0.548\\\\\n",
      "5 & (16/46) & 0.508\\\\\n",
      "6 & (9/26) & 0.500\\\\\n",
      "7 & (1/8) & 0.222\\\\\n",
      "8 & (2/5) & 0.571\\\\\n",
      "9 & (0/1) & 0.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/1) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.701438848921\n",
      "****************************** heldout_041/epoch_16 <rms ******************************\n",
      "FP 344\n",
      "TP 1215\n",
      "FN 731\n",
      "type ******************************\n",
      "del & (2/89) & 0.041\\\\\n",
      "rep & (900/1070) & 0.881\\\\\n",
      "sub & (313/787) & 0.459\\\\\n",
      "0.624357656732\n",
      "len ******************************\n",
      "1 & (869/1099) & 0.824\\\\\n",
      "2 & (270/468) & 0.629\\\\\n",
      "3 & (53/205) & 0.338\\\\\n",
      "4 & (19/87) & 0.302\\\\\n",
      "5 & (4/45) & 0.151\\\\\n",
      "6 & (0/25) & 0.000\\\\\n",
      "7 & (0/8) & 0.000\\\\\n",
      "8 & (0/5) & 0.000\\\\\n",
      "9 & (0/1) & 0.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/1) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.624357656732\n",
      "****************************** heldout_021/epoch_40 <rps ******************************\n",
      "FP 270\n",
      "TP 1417\n",
      "FN 529\n",
      "type ******************************\n",
      "del & (30/101) & 0.451\\\\\n",
      "rep & (885/1001) & 0.926\\\\\n",
      "sub & (502/844) & 0.644\\\\\n",
      "0.72816032888\n",
      "len ******************************\n",
      "0 & (0/1) & 0.000\\\\\n",
      "1 & (911/1096) & 0.878\\\\\n",
      "2 & (332/467) & 0.738\\\\\n",
      "3 & (100/205) & 0.580\\\\\n",
      "4 & (44/88) & 0.543\\\\\n",
      "5 & (16/46) & 0.500\\\\\n",
      "6 & (9/26) & 0.500\\\\\n",
      "7 & (3/8) & 0.545\\\\\n",
      "8 & (1/5) & 0.333\\\\\n",
      "9 & (1/1) & 1.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/1) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.72816032888\n",
      "****************************** heldout_021/epoch_40 <rms ******************************\n",
      "FP 370\n",
      "TP 1280\n",
      "FN 666\n",
      "type ******************************\n",
      "del & (0/79) & 0.000\\\\\n",
      "rep & (907/1069) & 0.882\\\\\n",
      "sub & (372/797) & 0.511\\\\\n",
      "0.657583547558\n",
      "len ******************************\n",
      "1 & (867/1095) & 0.842\\\\\n",
      "2 & (306/468) & 0.666\\\\\n",
      "3 & (77/207) & 0.439\\\\\n",
      "4 & (27/88) & 0.327\\\\\n",
      "5 & (3/46) & 0.103\\\\\n",
      "6 & (0/25) & 0.000\\\\\n",
      "7 & (0/8) & 0.000\\\\\n",
      "8 & (0/5) & 0.000\\\\\n",
      "9 & (0/1) & 0.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/1) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.65775950668\n"
     ]
    }
   ],
   "source": [
    "#Error analyses on exact match ('rms') and getting the right repair start ('rps')\n",
    "target_tags = [\n",
    "    '<rms',\n",
    "    '<rps',\n",
    "    #'<e'\n",
    "    ]\n",
    "\n",
    "for div,all_error in all_error_dicts.items():\n",
    "    # print div, type(all_error)\n",
    "   \n",
    "    if type(all_error) == bool: continue\n",
    "    if \"test\" in div: continue\n",
    "    #if not 'TTO only' in div or \"asr\" in div: continue\n",
    "    for tag, errors in all_error.items():\n",
    "        if tag not in target_tags:\n",
    "            continue\n",
    "        print \"*\" * 30, div, tag, \"*\" * 30\n",
    "        # print errors\n",
    "        # continue\n",
    "        #if not 'TTO only' in div or \"asr\" in div: continue\n",
    "        error = {\"TP\" : {}, \"FP\" : {}, \"FN\": {} }\n",
    "        for k,v in errors.items():\n",
    "            #if k == \"FP\":\n",
    "            #    continue\n",
    "            print k, len(v)\n",
    "            typedict = defaultdict(int)\n",
    "            lendict = defaultdict(int)\n",
    "            for repair in v:\n",
    "\n",
    "                #print repair.gold_context\n",
    "                onset = \"\"\n",
    "                if tag == \"<rps\" or tag == \"<rms\":\n",
    "                    \n",
    "                    \n",
    "                    for i in range(0,len(repair.gold_context)):\n",
    "                        if repair.gold_context[i] == \"+|+\":\n",
    "                            onset = repair.gold_context[i+1]\n",
    "                            break\n",
    "\n",
    "                    word = onset.split(\"|\")[0]\n",
    "                    #if k == \"FP\":\n",
    "                    #    onset = gold_onset\n",
    "                    if \"<e\" in onset and not tag == \"<e\":\n",
    "                        typedict[\"<e\"]+=1\n",
    "                    else:\n",
    "                        if word in [\"and\",\"or\",\"but\",\"so\",\"because\",\"that\",\"although\"]:\n",
    "                            typedict[\"CC\"]+=1\n",
    "                        elif word in [\"i\",\"we\",\"they\",\"im\",\"ive\",\"he\",\"she\",\"id\"]:\n",
    "                            typedict[\"subj\"]+=1\n",
    "                        elif word in [\"you\",\"the\"] or \"$\" in word:\n",
    "                            typedict[\"proper_other\"]+=1\n",
    "                        elif word in [\"yeah\",\"no\",\"okay\",\"yes\",\"right\",\"uh-huh\"]:\n",
    "                            typedict[\"ack\"]+=1\n",
    "                        elif word in [\"it\",\"its\"]:\n",
    "                            typedict[\"it\"]+=1\n",
    "                        else:\n",
    "                            typedict[word]+=1\n",
    "                \n",
    "                if tag == \"<rps\" or tag == \"<rms\": # and not k == 'FP':\n",
    "                    if k == \"TP\" and len(repair.reparandumWords) > 8:\n",
    "                        # should not be getting any over 8 words\n",
    "                        print \"** overlength repair!\"\n",
    "                        print repair\n",
    "                    lendict[len(repair.reparandumWords) + len(repair.interregnumWords)]+=1\n",
    "                    repair_type = None\n",
    "                    if repair.type:\n",
    "                        repair_type = repair.type \n",
    "                        typedict[repair_type]+=1\n",
    "\n",
    "            error[k]['len'] = deepcopy(lendict)\n",
    "            error[k]['type'] = deepcopy(typedict)\n",
    "\n",
    "                \n",
    "        for mode in ['type', 'len']:\n",
    "            #q1. THE RECALL RATES FOR VARIOUS GOLD REPAIR TYPES\n",
    "            print mode, \"*\" * 30\n",
    "            tps = error['TP'][mode]\n",
    "            fns = error['FN'][mode]\n",
    "            fps = error['FP'][mode]\n",
    "\n",
    "            total_tps = 0\n",
    "            total_fns = 0\n",
    "            total_fps = 0\n",
    "            top_n = 50\n",
    "            all_items = list(set(tps.keys() + fns.keys()))\n",
    "            # print all_items\n",
    "            for k in sorted(all_items,  reverse=False):\n",
    "                #print k, \"*\" * 30\n",
    "                if mode == 'type' and k not in [\"rep\", \"del\", \"sub\"]:\n",
    "                    continue\n",
    "                recall_total = tps[k] + fns[k]\n",
    "                recall = 0 if tps[k] == 0 else tps[k]/recall_total\n",
    "                precision_total = tps[k] + fps[k]\n",
    "                precision = 0 if tps[k] == 0 else tps[k]/precision_total\n",
    "                fscore = 0 if precision == 0 or recall == 0 else (2 * (precision * recall))/(precision + recall)\n",
    "                # print k, ':', tps[k], \"out of\", recall_total\n",
    "                #print k, ':', tps[k], \"out of\", precision_total\n",
    "                total_tps += tps[k]\n",
    "                total_fns += fns[k]\n",
    "                total_fps += fps[k]\n",
    "                print \" & \".join([str(k), \"({0}/{1})\".format(tps[k],recall_total), \n",
    "                                  '{0:.3f}'.format(fscore)]) + \"\\\\\\\\\"\n",
    "                top_n-=1\n",
    "                if top_n <= 0:\n",
    "                    break\n",
    "            print total_tps/(total_fns + total_tps)\n",
    "\n",
    "            if False:\n",
    "                #q2. ERROR TYPE SUMMARY\n",
    "                print \"*\" * 30\n",
    "                total = sum(fns.values()+tps.values())\n",
    "\n",
    "                errormass = 0\n",
    "                errortotal = 0\n",
    "                top_n = 20\n",
    "                for k,v in sorted(tps.items(),key= lambda x: x[1],reverse=True):\n",
    "                    print k,\"&\",v,\"&\",'{0:.2f}'.format(v/total)\n",
    "                    errormass +=(v/total * 100)\n",
    "                    errortotal+=v\n",
    "                    top_n-=1\n",
    "                    if top_n <= 0: break\n",
    "                print \"total &\",errortotal,\"&\",'{0:.2f}'.format(errormass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
